{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "australian-pointer",
   "metadata": {},
   "source": [
    "Subset the data in the way to obtain better utility with the same attack strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "exceptional-spokesman",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"C:\\\\Users\\\\tsarcevic\\\\PycharmProjects\\\\fingerprinting-toolbox\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "artistic-liberty",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from scipy.stats import chi2\n",
    "from imblearn.under_sampling import *\n",
    "\n",
    "from datasets import GermanCredit\n",
    "from attacks import *\n",
    "from parameter_guidelines.guidelines import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "molecular-integrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('parameter_guidelines/evaluation/german_credit/rel_horizontal_attack_utility_loss_gb_fpattr20.pickle', 'rb') as infile:\n",
    "    utility_loss_20 = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "molecular-secretary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.17047550469968925"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([np.mean(ut) for ut in utility_loss_20[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "based-offering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.16551512417162523,\n",
       " -0.19166930571028606,\n",
       " -0.17783569503314728,\n",
       " -0.15610926180518256,\n",
       " -0.17162812157756382,\n",
       " -0.16194149497545085,\n",
       " -0.16703437969470697,\n",
       " -0.1719627167646843,\n",
       " -0.16639581873191425,\n",
       " -0.1746631285323312]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.mean(ut) for ut in utility_loss_20[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "developed-distribution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.30263158, -0.12025316, -0.17931034, -0.12080537, -0.10457516]),\n",
       " array([-0.31818182, -0.06      , -0.14788732, -0.12101911, -0.31125828]),\n",
       " array([-0.33757962, -0.0955414 , -0.25675676, -0.08391608, -0.11538462]),\n",
       " array([-0.33116883, -0.05960265, -0.17687075, -0.11486486, -0.09803922]),\n",
       " array([-0.36477987, -0.09090909, -0.16551724, -0.12080537, -0.11612903]),\n",
       " array([-0.30921053, -0.10322581, -0.18243243, -0.15483871, -0.06      ]),\n",
       " array([-0.30718954, -0.1025641 , -0.17687075, -0.13815789, -0.11038961]),\n",
       " array([-0.33974359, -0.10759494, -0.18791946, -0.13245033, -0.09210526]),\n",
       " array([-0.30718954, -0.10322581, -0.17931034, -0.11486486, -0.12738854]),\n",
       " array([-0.32692308, -0.12101911, -0.20134228, -0.12080537, -0.10322581])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utility_loss_20[1] # --> 5 folds, 10 exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "quantitative-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('parameter_guidelines/evaluation/german_credit/robustness_horizontal_universal_c95_ag05_fpattr20_e100.pickle', 'rb') as infile:\n",
    "    robustness_20 = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "oriented-kazakhstan",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.95,\n",
       " 1.11: 0.9,\n",
       " 1.25: 0.9,\n",
       " 1.43: 0.9,\n",
       " 1.67: 0.9,\n",
       " 2: 0.9,\n",
       " 2.5: 0.85,\n",
       " 3: 0.85,\n",
       " 4: 0.8,\n",
       " 5: 0.8,\n",
       " 6: 0.75,\n",
       " 7: 0.7,\n",
       " 8: 0.65,\n",
       " 9: 0.65,\n",
       " 10: 0.6,\n",
       " 12: 0.5,\n",
       " 15: 0.4,\n",
       " 18: 0.25}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robustness_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "quiet-season",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# adapted guidelines.py/attack_utility\n",
    "def attack_outlier_removal_utility(model, data, target, ppf_q, n_folds=10): # ppf_q is equivalent to attack strength\n",
    "    #data = data.to_numpy()\n",
    "    X = data.drop(target, axis=1).to_numpy()\n",
    "    y = data[target].to_numpy()\n",
    "    #print(data.loc[(data['target']==2) & (data['duration']>2.1) & (data['duration']<2.3) & (data['checking_account']>-0.46)\n",
    "    #              & (data['checking_account']<-0.45) & (data['credit_hist']<-2.3)])\n",
    "    #print(data.iloc[915].to_numpy())\n",
    "    #print(X)\n",
    "    #print(y)\n",
    "\n",
    "    # score = cross_val_score(model, X, y, cv=5)\n",
    "    accuracy = []\n",
    "    attack_strength = []\n",
    "    for fold in range(n_folds):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=fold, shuffle=True)\n",
    "        #print('####')\n",
    "        #print(X_train[185])\n",
    "        #print(y_train[185])\n",
    "        # Covariance matrix\n",
    "        covariance  = np.cov(X_train, rowvar=False)\n",
    "\n",
    "        # Covariance matrix power of -1\n",
    "        covariance_pm1 = np.linalg.matrix_power(covariance, -1)\n",
    "\n",
    "        # Center point\n",
    "        centerpoint = np.mean(X_train, axis=0)\n",
    "\n",
    "        # Distances between center point and \n",
    "        distances = []\n",
    "        for i, val in enumerate(X_train):\n",
    "            p1 = val\n",
    "            p2 = centerpoint\n",
    "            distance = (p1-p2).T.dot(covariance_pm1).dot(p1-p2)\n",
    "            distances.append(distance)\n",
    "        distances = np.array(distances)\n",
    "\n",
    "        # Cutoff (threshold) value from Chi-Sqaure Distribution for detecting outliers \n",
    "        cutoff = chi2.ppf(ppf_q, X_train.shape[1])   # <------ to reduce #outliers, increase the first parameter\n",
    "\n",
    "        # Index of outliers\n",
    "        outlierIndexes = np.where(distances > cutoff )\n",
    "\n",
    "        print('--- Number of Outliers ----')\n",
    "        attack_strength.append(len(outlierIndexes[0])/X_train.shape[0])\n",
    "        print(str(len(outlierIndexes[0])) + \" ({}%)\".format(100*len(outlierIndexes[0])/X_train.shape[0]))\n",
    "\n",
    "        print('--- Index of Outliers ----')\n",
    "        print(outlierIndexes)\n",
    "        # array([ 88, 185, 236, 266, 512, 520, 564, 602, 681, 682, 729, 761]\n",
    "\n",
    "        #print('--- Observations found as outlier -----')\n",
    "        #print(X_train[distances > cutoff , :])\n",
    "        #print(y_train[distances > cutoff])\n",
    "        #attacked_train = pd.concat([X_train[distances > cutoff , :], y_train[distances > cutoff]], axis=1)\n",
    "        \n",
    "        #print('--- Observations without outliers ------')\n",
    "        #print(X_train[distances <= cutoff , :])\n",
    "        #print(y_train[distances <= cutoff])\n",
    "        attacked_X = X_train[distances <= cutoff , :]\n",
    "        attacked_y = y_train[distances <= cutoff]\n",
    "\n",
    "        model.fit(attacked_X, attacked_y)\n",
    "        acc = accuracy_score(y_test, model.predict(X_test))\n",
    "        accuracy.append(acc)\n",
    "    return accuracy, attack_strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "refined-photograph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Number of Outliers ----\n",
      "321 (40.125%)\n",
      "--- Index of Outliers ----\n",
      "(array([  0,   2,   4,   6,   7,   9,  10,  17,  18,  19,  21,  25,  27,\n",
      "        28,  32,  34,  36,  38,  39,  40,  42,  46,  48,  51,  52,  54,\n",
      "        57,  60,  63,  64,  67,  71,  74,  77,  78,  81,  82,  86,  88,\n",
      "        96,  98, 100, 106, 108, 109, 110, 111, 114, 117, 128, 129, 130,\n",
      "       137, 139, 144, 149, 151, 156, 158, 159, 161, 162, 163, 166, 169,\n",
      "       170, 171, 172, 174, 175, 176, 179, 181, 182, 185, 197, 201, 206,\n",
      "       209, 219, 220, 222, 225, 228, 229, 234, 236, 242, 246, 247, 248,\n",
      "       251, 252, 254, 264, 266, 268, 269, 274, 275, 276, 277, 279, 282,\n",
      "       283, 284, 289, 291, 292, 293, 294, 296, 299, 303, 304, 305, 306,\n",
      "       312, 315, 316, 320, 323, 324, 325, 327, 333, 335, 337, 340, 346,\n",
      "       348, 350, 351, 352, 355, 357, 358, 365, 366, 368, 370, 371, 376,\n",
      "       385, 387, 388, 391, 392, 395, 398, 401, 403, 404, 406, 407, 408,\n",
      "       410, 411, 412, 416, 417, 420, 421, 422, 424, 428, 438, 443, 448,\n",
      "       450, 451, 452, 453, 456, 458, 460, 462, 465, 468, 477, 478, 479,\n",
      "       480, 487, 489, 490, 494, 495, 497, 499, 500, 501, 502, 504, 505,\n",
      "       508, 511, 512, 514, 519, 520, 521, 522, 525, 527, 530, 532, 536,\n",
      "       537, 548, 554, 555, 556, 564, 566, 567, 568, 569, 570, 571, 573,\n",
      "       577, 578, 579, 582, 585, 586, 588, 590, 592, 595, 598, 601, 602,\n",
      "       605, 609, 611, 613, 620, 624, 628, 630, 633, 635, 637, 641, 642,\n",
      "       643, 646, 653, 654, 655, 658, 661, 671, 674, 676, 677, 680, 681,\n",
      "       682, 684, 685, 686, 688, 689, 690, 691, 693, 696, 697, 701, 702,\n",
      "       706, 707, 708, 709, 711, 713, 714, 717, 720, 722, 723, 724, 725,\n",
      "       726, 727, 728, 729, 730, 732, 744, 745, 746, 749, 750, 752, 754,\n",
      "       756, 760, 761, 763, 767, 769, 770, 773, 777, 778, 781, 782, 783,\n",
      "       786, 787, 789, 793, 794, 795, 797, 798, 799], dtype=int64),)\n",
      "--- Number of Outliers ----\n",
      "315 (39.375%)\n",
      "--- Index of Outliers ----\n",
      "(array([  2,   3,  12,  13,  15,  18,  19,  21,  22,  29,  30,  35,  37,\n",
      "        38,  40,  41,  42,  43,  46,  47,  52,  56,  58,  60,  62,  68,\n",
      "        69,  74,  76,  77,  87,  98,  99, 100, 103, 106, 107, 108, 110,\n",
      "       114, 116, 118, 124, 125, 129, 133, 137, 141, 144, 145, 147, 148,\n",
      "       150, 151, 155, 156, 158, 159, 161, 164, 165, 173, 174, 179, 180,\n",
      "       182, 184, 185, 186, 188, 189, 194, 199, 202, 207, 209, 211, 216,\n",
      "       217, 220, 221, 222, 223, 225, 228, 231, 233, 234, 239, 240, 242,\n",
      "       243, 245, 247, 248, 250, 251, 252, 254, 257, 261, 263, 264, 265,\n",
      "       266, 268, 270, 271, 272, 275, 278, 279, 282, 283, 289, 291, 292,\n",
      "       294, 299, 300, 303, 304, 309, 310, 311, 312, 314, 319, 324, 336,\n",
      "       340, 341, 342, 344, 346, 347, 348, 350, 354, 356, 357, 359, 362,\n",
      "       364, 365, 366, 372, 374, 376, 377, 378, 379, 383, 387, 390, 395,\n",
      "       397, 399, 403, 404, 405, 409, 413, 414, 418, 419, 420, 421, 422,\n",
      "       423, 425, 427, 429, 430, 437, 438, 443, 450, 451, 454, 456, 460,\n",
      "       462, 463, 464, 467, 468, 473, 474, 475, 481, 482, 485, 492, 493,\n",
      "       494, 496, 499, 505, 506, 511, 516, 521, 522, 524, 525, 529, 535,\n",
      "       538, 542, 543, 544, 547, 550, 553, 554, 556, 559, 561, 562, 563,\n",
      "       564, 567, 569, 572, 573, 575, 579, 581, 583, 594, 596, 597, 598,\n",
      "       599, 601, 603, 604, 606, 607, 608, 611, 612, 616, 617, 618, 624,\n",
      "       625, 626, 629, 632, 636, 637, 642, 644, 646, 650, 656, 659, 664,\n",
      "       667, 668, 671, 675, 676, 677, 678, 679, 687, 689, 690, 695, 697,\n",
      "       700, 701, 702, 707, 708, 711, 712, 713, 714, 715, 718, 719, 722,\n",
      "       725, 726, 727, 729, 731, 733, 737, 738, 739, 741, 744, 745, 746,\n",
      "       748, 749, 750, 751, 752, 757, 758, 764, 768, 770, 771, 774, 786,\n",
      "       787, 794, 796], dtype=int64),)\n",
      "--- Number of Outliers ----\n",
      "319 (39.875%)\n",
      "--- Index of Outliers ----\n",
      "(array([  0,   1,   2,   4,   7,  15,  16,  17,  18,  19,  24,  26,  27,\n",
      "        28,  29,  31,  32,  33,  35,  39,  42,  45,  47,  50,  52,  54,\n",
      "        57,  58,  60,  63,  65,  66,  68,  69,  70,  71,  73,  76,  78,\n",
      "        83,  93, 100, 103, 104, 107, 110, 111, 112, 114, 121, 124, 127,\n",
      "       130, 133, 136, 137, 138, 142, 143, 144, 149, 150, 152, 155, 156,\n",
      "       157, 173, 174, 176, 178, 179, 181, 182, 183, 185, 187, 188, 194,\n",
      "       195, 197, 198, 205, 212, 218, 219, 221, 226, 228, 230, 232, 234,\n",
      "       235, 237, 238, 241, 246, 248, 249, 251, 253, 254, 255, 257, 259,\n",
      "       260, 262, 263, 264, 266, 270, 271, 276, 278, 280, 283, 285, 286,\n",
      "       288, 290, 291, 292, 293, 295, 297, 303, 305, 310, 312, 317, 322,\n",
      "       326, 329, 330, 332, 336, 337, 339, 342, 345, 347, 348, 353, 356,\n",
      "       357, 358, 359, 360, 363, 365, 368, 370, 374, 377, 378, 380, 381,\n",
      "       385, 389, 390, 391, 394, 395, 397, 401, 404, 406, 407, 408, 409,\n",
      "       412, 413, 420, 425, 426, 427, 428, 431, 434, 436, 438, 440, 441,\n",
      "       442, 443, 444, 446, 447, 451, 452, 453, 455, 458, 461, 462, 464,\n",
      "       468, 469, 470, 473, 474, 475, 476, 477, 478, 484, 486, 487, 493,\n",
      "       495, 497, 499, 501, 503, 504, 505, 511, 514, 516, 517, 518, 522,\n",
      "       524, 527, 530, 536, 538, 542, 543, 544, 546, 548, 552, 553, 554,\n",
      "       559, 562, 563, 564, 567, 572, 573, 578, 579, 581, 589, 590, 593,\n",
      "       595, 602, 604, 611, 616, 618, 623, 626, 627, 628, 630, 631, 632,\n",
      "       637, 639, 641, 647, 648, 649, 650, 653, 656, 661, 666, 667, 670,\n",
      "       672, 673, 675, 676, 678, 680, 682, 683, 697, 701, 706, 707, 710,\n",
      "       711, 716, 717, 719, 720, 726, 729, 732, 734, 743, 744, 746, 747,\n",
      "       751, 753, 755, 757, 759, 762, 764, 765, 767, 772, 780, 782, 784,\n",
      "       788, 789, 790, 791, 792, 793, 796], dtype=int64),)\n",
      "--- Number of Outliers ----\n",
      "317 (39.625%)\n",
      "--- Index of Outliers ----\n",
      "(array([  0,   1,   3,   5,   7,   8,  15,  18,  22,  24,  25,  30,  31,\n",
      "        37,  38,  42,  43,  45,  46,  49,  52,  54,  55,  56,  57,  59,\n",
      "        60,  61,  62,  67,  68,  71,  74,  80,  81,  87,  92,  95,  98,\n",
      "        99, 103, 104, 107, 115, 119, 120, 122, 123, 129, 136, 137, 139,\n",
      "       140, 144, 145, 151, 152, 154, 156, 157, 159, 160, 161, 163, 165,\n",
      "       166, 167, 168, 170, 172, 174, 175, 176, 178, 179, 180, 181, 183,\n",
      "       185, 186, 188, 189, 195, 197, 199, 201, 202, 203, 206, 208, 211,\n",
      "       213, 217, 218, 222, 224, 225, 226, 229, 235, 239, 242, 248, 249,\n",
      "       250, 251, 254, 255, 257, 263, 264, 266, 268, 271, 274, 280, 283,\n",
      "       288, 292, 297, 300, 301, 303, 304, 307, 309, 311, 313, 314, 317,\n",
      "       319, 325, 327, 332, 334, 335, 339, 340, 341, 348, 350, 351, 354,\n",
      "       357, 358, 365, 366, 369, 372, 373, 374, 375, 378, 382, 385, 390,\n",
      "       391, 393, 395, 401, 402, 404, 405, 406, 408, 409, 417, 418, 419,\n",
      "       423, 427, 428, 429, 432, 433, 437, 438, 443, 444, 445, 446, 447,\n",
      "       448, 452, 453, 454, 456, 458, 460, 461, 463, 465, 466, 469, 474,\n",
      "       477, 481, 484, 492, 493, 496, 498, 499, 505, 507, 508, 511, 515,\n",
      "       522, 523, 526, 528, 530, 533, 542, 543, 549, 550, 552, 553, 555,\n",
      "       561, 562, 563, 566, 570, 573, 574, 581, 582, 583, 587, 589, 590,\n",
      "       591, 594, 598, 599, 600, 601, 602, 603, 609, 614, 615, 616, 619,\n",
      "       620, 624, 628, 630, 634, 636, 641, 643, 649, 650, 654, 656, 658,\n",
      "       659, 663, 666, 667, 670, 671, 672, 675, 679, 683, 685, 688, 692,\n",
      "       693, 694, 695, 697, 699, 700, 706, 707, 714, 717, 719, 721, 722,\n",
      "       723, 725, 726, 727, 729, 730, 731, 732, 734, 735, 737, 738, 739,\n",
      "       741, 747, 752, 754, 758, 761, 763, 765, 767, 769, 778, 781, 786,\n",
      "       787, 790, 791, 792, 797], dtype=int64),)\n",
      "--- Number of Outliers ----\n",
      "321 (40.125%)\n",
      "--- Index of Outliers ----\n",
      "(array([  1,   4,   5,   6,   7,   8,   9,  10,  12,  14,  15,  18,  20,\n",
      "        26,  27,  28,  30,  33,  39,  40,  41,  43,  44,  46,  50,  54,\n",
      "        55,  57,  60,  61,  63,  65,  66,  67,  68,  69,  70,  75,  76,\n",
      "        77,  78,  81,  82,  83,  84,  85,  87,  89,  90, 103, 105, 106,\n",
      "       109, 113, 114, 116, 117, 121, 123, 126, 127, 130, 131, 132, 133,\n",
      "       135, 137, 138, 140, 149, 153, 156, 157, 162, 165, 167, 168, 169,\n",
      "       171, 172, 173, 174, 177, 185, 190, 192, 193, 196, 199, 200, 201,\n",
      "       202, 216, 217, 226, 227, 233, 236, 237, 238, 239, 241, 244, 245,\n",
      "       246, 247, 251, 253, 254, 255, 256, 259, 262, 264, 265, 266, 268,\n",
      "       270, 271, 272, 273, 276, 278, 279, 280, 281, 283, 284, 286, 288,\n",
      "       289, 291, 294, 297, 299, 300, 301, 305, 311, 313, 318, 321, 327,\n",
      "       333, 334, 340, 341, 343, 351, 353, 356, 360, 362, 366, 373, 377,\n",
      "       384, 387, 389, 391, 392, 396, 398, 399, 401, 402, 403, 404, 405,\n",
      "       407, 412, 414, 415, 416, 418, 423, 426, 427, 428, 434, 436, 437,\n",
      "       440, 441, 444, 446, 447, 451, 454, 460, 461, 464, 465, 466, 467,\n",
      "       474, 476, 479, 481, 483, 484, 486, 487, 490, 491, 492, 500, 501,\n",
      "       504, 505, 509, 511, 514, 516, 519, 520, 525, 530, 532, 536, 538,\n",
      "       543, 549, 565, 566, 575, 577, 578, 581, 584, 587, 592, 595, 600,\n",
      "       601, 602, 606, 609, 610, 617, 620, 623, 624, 625, 627, 633, 635,\n",
      "       636, 639, 642, 649, 658, 659, 661, 664, 671, 672, 674, 675, 676,\n",
      "       677, 683, 686, 687, 692, 693, 695, 696, 698, 700, 703, 704, 707,\n",
      "       708, 710, 711, 713, 714, 716, 717, 726, 729, 730, 731, 733, 734,\n",
      "       735, 736, 739, 740, 742, 744, 746, 748, 749, 751, 754, 756, 757,\n",
      "       758, 759, 760, 761, 762, 763, 765, 767, 773, 774, 775, 777, 778,\n",
      "       783, 785, 786, 787, 791, 792, 793, 794, 795], dtype=int64),)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.715, 0.755, 0.71, 0.73, 0.7],\n",
       " [0.40125, 0.39375, 0.39875, 0.39625, 0.40125])"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_dir = \"parameter_guidelines/fingerprinted_data/german_credit/attr_subset_20/\"\n",
    "fingerprinted_data = pd.read_csv(fp_dir + \"universal_g{}_x1_l8_u1_sk0.csv\".format(gamma))\n",
    "data = GermanCredit().preprocessed(fp_data=fingerprinted_data)\n",
    "\n",
    "attack_outlier_removal_utility(ppf_q=0.57, \n",
    "                               model=GradientBoostingClassifier(random_state=9), \n",
    "                               data=data, \n",
    "                               target='target', \n",
    "                               n_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "surrounded-principle",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_attack_utilities = dict()  # dict(gamma:accuracies 5 fold); attack_strength = robustness_20[gamma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "thorough-scale",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8549999999999999"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([0.8525, 0.85125, 0.86, 0.845, 0.86625])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "legislative-dollar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.742"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([0.72, 0.75, 0.715, 0.74, 0.785])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "entitled-credits",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_attack_utilities[18] = [0.72, 0.75, 0.715, 0.74, 0.785]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "intellectual-pavilion",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_attack_utilities = dict(collections.OrderedDict(sorted(outlier_attack_utilities.items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "legitimate-province",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_attack_utilities['baseline'] = outlier_attack_utilities[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "instant-longitude",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [0.585, 0.685, 0.585, 0.56, 0.65],\n",
       " 1.11: [0.64, 0.71, 0.635, 0.61, 0.645],\n",
       " 1.25: [0.64, 0.71, 0.635, 0.61, 0.645],\n",
       " 1.43: [0.64, 0.71, 0.635, 0.61, 0.645],\n",
       " 1.67: [0.64, 0.71, 0.635, 0.61, 0.645],\n",
       " 2: [0.64, 0.71, 0.635, 0.61, 0.645],\n",
       " 2.5: [0.595, 0.685, 0.715, 0.65, 0.645],\n",
       " 3: [0.595, 0.685, 0.715, 0.65, 0.645],\n",
       " 4: [0.635, 0.69, 0.7, 0.68, 0.64],\n",
       " 5: [0.635, 0.69, 0.7, 0.68, 0.64],\n",
       " 6: [0.69, 0.7, 0.715, 0.69, 0.7],\n",
       " 7: [0.675, 0.735, 0.69, 0.725, 0.7],\n",
       " 8: [0.71, 0.765, 0.71, 0.7, 0.71],\n",
       " 9: [0.71, 0.765, 0.71, 0.7, 0.71],\n",
       " 10: [0.7, 0.755, 0.72, 0.675, 0.715],\n",
       " 12: [0.74, 0.74, 0.715, 0.7, 0.76],\n",
       " 15: [0.715, 0.755, 0.71, 0.73, 0.7],\n",
       " 18: [0.72, 0.75, 0.715, 0.74, 0.785],\n",
       " 'baseline': [0.73, 0.785, 0.745, 0.755, 0.765]}"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_attack_utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "meaning-capture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01369863, -0.04458599, -0.04026846, -0.01986755,  0.02614379])"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(outlier_attack_utilities[18]) - np.array(outlier_attack_utilities['baseline'])) / np.array(outlier_attack_utilities['baseline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "potential-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO redo the baselines!!\n",
    "baselines = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "settled-klein",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('parameter_guidelines/evaluation/german_credit/outlier_attack_utilities_fpattr20_sk0.pkl', 'wb') as outfile:\n",
    "    pickle.dump(outlier_attack_utilities, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "suitable-inspection",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 20)\n",
      "[0.73, 0.785, 0.745, 0.755, 0.765]\n",
      "0.756\n",
      "(800, 20)\n",
      "[0.75, 0.765, 0.715, 0.735, 0.76]\n",
      "0.7449999999999999\n",
      "(800, 20)\n",
      "[0.775, 0.775, 0.715, 0.725, 0.76]\n",
      "0.75\n",
      "(800, 20)\n",
      "[0.78, 0.765, 0.71, 0.73, 0.765]\n",
      "0.75\n",
      "(800, 20)\n",
      "[0.765, 0.775, 0.73, 0.745, 0.735]\n",
      "0.75\n",
      "(800, 20)\n",
      "[0.75, 0.765, 0.755, 0.765, 0.775]\n",
      "0.762\n",
      "(800, 20)\n",
      "[0.785, 0.77, 0.715, 0.74, 0.73]\n",
      "0.748\n",
      "(800, 20)\n",
      "[0.77, 0.79, 0.725, 0.74, 0.775]\n",
      "0.76\n",
      "(800, 20)\n",
      "[0.775, 0.81, 0.735, 0.745, 0.75]\n",
      "0.763\n",
      "(800, 20)\n",
      "[0.76, 0.775, 0.765, 0.755, 0.765]\n",
      "0.764\n",
      "(800, 20)\n",
      "[0.755, 0.77, 0.72, 0.74, 0.745]\n",
      "0.7460000000000001\n",
      "(800, 20)\n",
      "[0.775, 0.78, 0.76, 0.76, 0.75]\n",
      "0.765\n",
      "(800, 20)\n",
      "[0.775, 0.78, 0.73, 0.72, 0.77]\n",
      "0.755\n",
      "(800, 20)\n",
      "[0.775, 0.775, 0.74, 0.77, 0.775]\n",
      "0.767\n",
      "(800, 20)\n",
      "[0.765, 0.765, 0.735, 0.765, 0.765]\n",
      "0.7590000000000001\n",
      "(800, 20)\n",
      "[0.785, 0.78, 0.735, 0.72, 0.745]\n",
      "0.7529999999999999\n",
      "(800, 20)\n",
      "[0.775, 0.77, 0.73, 0.76, 0.75]\n",
      "0.757\n",
      "(800, 20)\n",
      "[0.76, 0.765, 0.745, 0.765, 0.755]\n",
      "0.758\n"
     ]
    }
   ],
   "source": [
    "# BASELINES\n",
    "gamma = [1, 1.11, 1.25, 1.43, 1.67, 2, 2.5, 3, 4, 5, 6, 7, 8, 9, 10, 12, 15, 18]\n",
    "for g in gamma:\n",
    "    fp_dir = \"parameter_guidelines/fingerprinted_data/german_credit/attr_subset_20/\"\n",
    "    fingerprinted_data = pd.read_csv(fp_dir + \"universal_g{}_x1_l8_u1_sk0.csv\".format(g))\n",
    "    data = GermanCredit().preprocessed(fp_data=fingerprinted_data)\n",
    "    #data = data.to_numpy()\n",
    "    X = data.drop('target', axis=1).to_numpy()\n",
    "    y = data[target]\n",
    "\n",
    "    # score = cross_val_score(model, X, y, cv=5)\n",
    "    accuracy = []\n",
    "    for fold in range(5):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=fold, shuffle=True)\n",
    "        #X_train = X_train[:-750, :]\n",
    "        #y_train = y_train[:-750]\n",
    "\n",
    "        model = GradientBoostingClassifier(random_state=9)\n",
    "        model.fit(X_train, y_train)\n",
    "        acc = accuracy_score(y_test, model.predict(X_test))\n",
    "        accuracy.append(acc)\n",
    "    print(X_train.shape)\n",
    "    print(accuracy)\n",
    "    print(np.mean(accuracy))\n",
    "    baselines[g] = accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sporting-berlin",
   "metadata": {},
   "source": [
    "gamma=1 sk=0\n",
    "(800, 20)\n",
    "[0.73, 0.785, 0.745, 0.755, 0.765]\n",
    "0.756 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "unsigned-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_loss = dict()\n",
    "for gamma in baselines:\n",
    "    rel_loss[gamma] = (np.array(outlier_attack_utilities[gamma]) - np.array(baselines[gamma])) / np.array(outlier_attack_utilities[gamma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "square-balance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: array([-0.24786325, -0.1459854 , -0.27350427, -0.34821429, -0.17692308]),\n",
       " 1.11: array([-0.171875  , -0.07746479, -0.12598425, -0.20491803, -0.17829457]),\n",
       " 1.25: array([-0.2109375 , -0.0915493 , -0.12598425, -0.18852459, -0.17829457]),\n",
       " 1.43: array([-0.21875   , -0.07746479, -0.11811024, -0.19672131, -0.18604651]),\n",
       " 1.67: array([-0.1953125 , -0.0915493 , -0.1496063 , -0.22131148, -0.13953488]),\n",
       " 2: array([-0.171875  , -0.07746479, -0.18897638, -0.25409836, -0.20155039]),\n",
       " 2.5: array([-0.31932773, -0.12408759,  0.        , -0.13846154, -0.13178295]),\n",
       " 3: array([-0.29411765, -0.15328467, -0.01398601, -0.13846154, -0.20155039]),\n",
       " 4: array([-0.22047244, -0.17391304, -0.05      , -0.09558824, -0.171875  ]),\n",
       " 5: array([-0.19685039, -0.12318841, -0.09285714, -0.11029412, -0.1953125 ]),\n",
       " 6: array([-0.0942029 , -0.1       , -0.00699301, -0.07246377, -0.06428571]),\n",
       " 7: array([-0.14814815, -0.06122449, -0.10144928, -0.04827586, -0.07142857]),\n",
       " 8: array([-0.0915493 , -0.01960784, -0.02816901, -0.02857143, -0.08450704]),\n",
       " 9: array([-0.0915493 , -0.0130719 , -0.04225352, -0.1       , -0.0915493 ]),\n",
       " 10: array([-0.09285714, -0.01324503, -0.02083333, -0.13333333, -0.06993007]),\n",
       " 12: array([-0.06081081, -0.05405405, -0.02797203, -0.02857143,  0.01973684]),\n",
       " 15: array([-0.08391608, -0.01986755, -0.02816901, -0.04109589, -0.07142857]),\n",
       " 18: array([-0.05555556, -0.02      , -0.04195804, -0.03378378,  0.03821656])}"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "separated-december",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('parameter_guidelines/evaluation/german_credit/rel_outlier_attack_utilities_fpattr20_sk0.pkl', 'wb') as outfile:\n",
    "    pickle.dump(rel_loss, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "according-regulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "african-hardware",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate based on mahalonobis distance\n",
    "\n",
    "# Covariance matrix\n",
    "covariance  = np.cov(data , rowvar=False)\n",
    "\n",
    "# Covariance matrix power of -1\n",
    "covariance_pm1 = np.linalg.matrix_power(covariance, -1)\n",
    "\n",
    "# Center point\n",
    "centerpoint = np.mean(data , axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "super-brunei",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Number of Outliers ----\n",
      "55 (5.5%)\n",
      "--- Index of Outliers ----\n",
      "(array([ 17,  22,  24,  65,  95, 108, 117, 138, 140, 151, 156, 173, 175,\n",
      "       187, 197, 236, 237, 247, 264, 268, 290, 294, 297, 310, 314, 351,\n",
      "       381, 413, 429, 438, 465, 494, 505, 516, 552, 597, 613, 646, 696,\n",
      "       756, 763, 774, 818, 850, 859, 871, 889, 890, 892, 900, 906, 915,\n",
      "       917, 950, 972], dtype=int64),)\n",
      "--- Observations found as outlier -----\n",
      "[[-1.25456565  0.75476341 -2.35086999 ... -0.82331789 -0.19601428\n",
      "   1.        ]\n",
      " [-1.25456565 -0.90460432  1.34401408 ... -0.82331789  5.10166904\n",
      "   1.        ]\n",
      " [ 1.13205258 -0.90460432  1.34401408 ... -0.82331789  5.10166904\n",
      "   1.        ]\n",
      " ...\n",
      " [-1.25456565 -1.23647786 -0.50342796 ...  1.21459768 -0.19601428\n",
      "   2.        ]\n",
      " [-0.45902624 -0.24085723  1.34401408 ...  1.21459768 -0.19601428\n",
      "   1.        ]\n",
      " [-1.25456565  0.25695309 -1.42714898 ... -0.82331789 -0.19601428\n",
      "   2.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Distances between center point and \n",
    "distances = []\n",
    "for i, val in enumerate(data):\n",
    "      p1 = val\n",
    "      p2 = centerpoint\n",
    "      distance = (p1-p2).T.dot(covariance_pm1).dot(p1-p2)\n",
    "      distances.append(distance)\n",
    "distances = np.array(distances)\n",
    "\n",
    "# Cutoff (threshold) value from Chi-Sqaure Distribution for detecting outliers \n",
    "cutoff = chi2.ppf(0.99, data.shape[1])   # <------ to reduce #outliers, increase the first parameter\n",
    "\n",
    "# Index of outliers\n",
    "outlierIndexes = np.where(distances > cutoff )\n",
    "\n",
    "print('--- Number of Outliers ----')\n",
    "print(str(len(outlierIndexes[0])) + \" ({}%)\".format(100*len(outlierIndexes[0])/data.shape[0]))\n",
    "\n",
    "print('--- Index of Outliers ----')\n",
    "print(outlierIndexes)\n",
    "# array([24, 35, 67, 81])\n",
    "\n",
    "print('--- Observations found as outlier -----')\n",
    "print(data[ distances > cutoff , :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "behind-knitting",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LinearRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\TSARCE~1\\AppData\\Local\\Temp/ipykernel_1244/803126069.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# evaluate the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LinearRegression' is not defined"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print('MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-trigger",
   "metadata": {},
   "source": [
    "## Clustering approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-father",
   "metadata": {},
   "source": [
    "Targeted sub-sampling in a form of distribution-preserving subsampling. \n",
    "First, we cluster the data, then sample from the clusters based on their size. \n",
    "This can be experimented with a number of different cluster sizes. \n",
    "The goal is to obtain less accuracy loss by subsetting compared to random sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "exotic-south",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data\n",
    "data = GermanCredit().preprocessed()\n",
    "X = data.drop('target', axis=1).to_numpy()\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "centered-steal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fingerprinted data\n",
    "gamma=1\n",
    "fp_dir = \"parameter_guidelines/fingerprinted_data/german_credit/attr_subset_20/\"\n",
    "fingerprinted_data = pd.read_csv(fp_dir + \"universal_g{}_x1_l8_u1_sk0.csv\".format(gamma))\n",
    "fp_data = GermanCredit().preprocessed(fp_data=fingerprinted_data)\n",
    "#data = data.to_numpy()\n",
    "X_fp = fp_data.drop('target', axis=1)#.to_numpy()\n",
    "y_fp = fp_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "common-client",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8  , 0.735, 0.74 , 0.785, 0.745])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline\n",
    "score_baseline = fp_cross_val_score(GradientBoostingClassifier(random_state=9), X, y, X_fp, y_fp, scoring='accuracy')['test_score']\n",
    "score_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "physical-translator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will serve as a pipeline for cross validation attacked dataset\n",
    "def attack_cross_val_score(X, y, target, attack, attack_strength, n_folds=5):\n",
    "    accuracy = []\n",
    "    for fold in range(n_folds):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=fold, shuffle=True)\n",
    "        train = pd.concat([X_train, y_train], axis=1)\n",
    "        attacked_train = attack.run(train, attack_strength, random_state=fold)\n",
    "        attacked_X = attacked_train.drop(target, axis=1)\n",
    "        attacked_y = attacked_train[target]\n",
    "        model = GradientBoostingClassifier()\n",
    "        model.fit(attacked_X, attacked_y)\n",
    "        acc = accuracy_score(y_test, model.predict(X_test))\n",
    "        accuracy.append(acc)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "honey-appeal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.675, 0.74, 0.695, 0.68, 0.645]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random attack\n",
    "attack_utility_scores = attack_cross_val_score(X_fp, y_fp, 'target', HorizontalSubsetAttack(), 0.9)\n",
    "attack_utility_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "mobile-nitrogen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.687"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(attack_utility_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-oasis",
   "metadata": {},
   "source": [
    "### Targeted attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "reasonable-documentary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def targeted_attack_cross_val_score(X, y, attack_strength, n_folds=5, sampler_version=1, sampler_n_neighbors=3):\n",
    "    accuracy = []\n",
    "    for fold in range(n_folds):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=fold, shuffle=True)\n",
    "        train = pd.concat([X_train, y_train], axis=1)\n",
    "        sampler = NearMiss(version=sampler_version, \n",
    "                           sampling_strategy=strategy(attack_strength, y_train), \n",
    "                           n_neighbors=sampler_n_neighbors)\n",
    "        #sampler = InstanceHardnessThreshold(estimator=GradientBoostingClassifier(),\n",
    "        #                                    sampling_strategy=strategy(attack_strength, y_train)) -- some internal error\n",
    "        attacked_X, attacked_y = sampler.fit_resample(X_train, y_train)\n",
    "        model = GradientBoostingClassifier()\n",
    "        model.fit(attacked_X, attacked_y)\n",
    "        acc = accuracy_score(y_test, model.predict(X_test))\n",
    "        accuracy.append(acc)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eleven-nickel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strategy(attack_strength, y):\n",
    "    strategy = y.value_counts() * (1-attack_strength)\n",
    "    strategy = {key: round(x) for key, x in strategy.items()}\n",
    "    return strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "successful-football",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7050000000000001"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# targeted attack\n",
    "attack_utility_scores = targeted_attack_cross_val_score(X_fp, y_fp, 0.9)\n",
    "attack_utility_scores\n",
    "np.mean(attack_utility_scores) # version 1 ###### the best (and the only one actually better than random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "focused-catalog",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version 1\n",
      "{1: 0.6579999999999999, 2: 0.726, 3: 0.7230000000000001, 4: 0.73, 5: 0.7289999999999999, 6: 0.726, 7: 0.722, 8: 0.7089999999999999, 9: 0.716}\n",
      "0.73\n"
     ]
    }
   ],
   "source": [
    "# experimenting with the number of neighbors\n",
    "res = dict()\n",
    "for n in range(1, 10):\n",
    "    # targeted attack\n",
    "    attack_utility_scores = targeted_attack_cross_val_score(X_fp, y_fp, 0.7, sampler_n_neighbors=n) # 3 shows to be the best (default)\n",
    "    res[n] = np.mean(attack_utility_scores) # version 1 ###### the best (and the only one actually better than random)\n",
    "print('version 1')\n",
    "print(res)\n",
    "print(max(res.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "processed-garage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.605, 0.69, 0.655, 0.65, 0.655]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# targeted attack\n",
    "attack_utility_scores = targeted_attack_cross_val_score(X_fp, y_fp, 0.9, sampler_version=2)\n",
    "attack_utility_scores\n",
    "np.mean(attack_utility_scores) # version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "choice-projector",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6599999999999999"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# targeted attack\n",
    "attack_utility_scores = targeted_attack_cross_val_score(X_fp, y_fp, 0.9, sampler_version=3)\n",
    "np.mean(attack_utility_scores) # version 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-relaxation",
   "metadata": {},
   "source": [
    "The final decision is the sampler NearMiss, version 1, with default number of neighbors, 3\n",
    "\n",
    "In the following we create the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "advanced-doctrine",
   "metadata": {},
   "outputs": [],
   "source": [
    "robustness = dict()\n",
    "for i in [4,8,12,16,20]:\n",
    "    with open('parameter_guidelines/evaluation/german_credit/robustness_horizontal_universal_c95_ag05_fpattr{}_e100.pickle'.format(i), 'rb') as infile:\n",
    "        robustness[i] = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "unique-phenomenon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.9\n",
      "1.11 0.9\n",
      "1.25 0.9\n",
      "1.43 0.9\n",
      "1.67 0.9\n",
      "2 0.9\n",
      "2.5 0.85\n",
      "3 0.85\n",
      "4 0.8\n",
      "5 0.8\n",
      "6 0.75\n",
      "7 0.7\n",
      "8 0.65\n",
      "9 0.65\n",
      "10 0.6\n",
      "12 0.5\n",
      "15 0.4\n",
      "18 0.25\n"
     ]
    }
   ],
   "source": [
    "fpattr = 8\n",
    "n_exp = 10\n",
    "results = {gamma: [] for gamma in robustness[fpattr]}\n",
    "for gamma, attack_strength in robustness[fpattr].items():\n",
    "    print(gamma, attack_strength)\n",
    "    for exp in range(n_exp):\n",
    "        # take one fp ds\n",
    "        fp_dir = \"parameter_guidelines/fingerprinted_data/german_credit/attr_subset_{}/\".format(fpattr)\n",
    "        fingerprinted_data = pd.read_csv(fp_dir + \"universal_g{}_x1_l8_u1_sk{}.csv\".format(gamma, exp))\n",
    "        fp_data = GermanCredit().preprocessed(fp_data=fingerprinted_data)\n",
    "        #data = data.to_numpy()\n",
    "        X_fp = fp_data.drop('target', axis=1)#.to_numpy()\n",
    "        y_fp = fp_data['target']\n",
    "        \n",
    "        # calc baseline fp utility\n",
    "        score_baseline = fp_cross_val_score(GradientBoostingClassifier(random_state=9), X, y, X_fp, y_fp, scoring='accuracy')['test_score']\n",
    "\n",
    "        # calc attacked \n",
    "        attack_utility_scores = targeted_attack_cross_val_score(X_fp, y_fp, attack_strength)\n",
    "\n",
    "        # take relative loss\n",
    "        rel_loss = (score_baseline - attack_utility_scores) / score_baseline\n",
    "        results[gamma].append(rel_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "balanced-directory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [array([0.1875    , 0.08163265, 0.08783784, 0.23566879, 0.1409396 ]),\n",
       "  array([0.11538462, 0.125     , 0.24      , 0.22875817, 0.02758621]),\n",
       "  array([0.18709677, 0.28205128, 0.13815789, 0.09803922, 0.21192053]),\n",
       "  array([0.11643836, 0.2875817 , 0.31125828, 0.28571429, 0.26027397]),\n",
       "  array([0.11184211, 0.05960265, 0.17763158, 0.14379085, 0.14285714]),\n",
       "  array([0.06944444, 0.03896104, 0.24025974, 0.12666667, 0.14285714]),\n",
       "  array([0.38709677, 0.15584416, 0.1986755 , 0.24358974, 0.40909091]),\n",
       "  array([0.16556291, 0.13836478, 0.10596026, 0.2866242 , 0.31333333]),\n",
       "  array([0.12337662, 0.08496732, 0.36842105, 0.19871795, 0.19620253]),\n",
       "  array([0.19480519, 0.14012739, 0.12666667, 0.10810811, 0.09868421])],\n",
       " 1.11: [array([0.0738255 , 0.03896104, 0.11486486, 0.13636364, 0.125     ]),\n",
       "  array([0.05921053, 0.03289474, 0.16774194, 0.14012739, 0.02027027]),\n",
       "  array([0.14465409, 0.11038961, 0.11764706, 0.12903226, 0.10810811]),\n",
       "  array([0.03424658, 0.03246753, 0.08552632, 0.10666667, 0.09395973]),\n",
       "  array([0.11612903, 0.08974359, 0.12418301, 0.0516129 , 0.09210526]),\n",
       "  array([0.0472973 , 0.02597403, 0.14285714, 0.08163265, 0.12837838]),\n",
       "  array([0.15483871, 0.07096774, 0.14193548, 0.18831169, 0.14569536]),\n",
       "  array([0.03378378, 0.12101911, 0.14285714, 0.09868421, 0.03355705]),\n",
       "  array([0.14666667, 0.07692308, 0.1192053 , 0.08053691, 0.08      ]),\n",
       "  array([0.07792208, 0.12582781, 0.12987013, 0.01986755, 0.04635762])],\n",
       " 1.25: [array([0.12658228, 0.07843137, 0.09271523, 0.12903226, 0.04026846]),\n",
       "  array([0.02027027, 0.02721088, 0.11111111, 0.10897436, 0.14473684]),\n",
       "  array([0.07594937, 0.05263158, 0.1372549 , 0.04516129, 0.21768707]),\n",
       "  array([0.09933775, 0.06410256, 0.08724832, 0.18954248, 0.16233766]),\n",
       "  array([0.00653595, 0.04575163, 0.11258278, 0.09090909, 0.14379085]),\n",
       "  array([0.03378378, 0.06578947, 0.1483871 , 0.0979021 , 0.27210884]),\n",
       "  array([0.14569536, 0.11111111, 0.1474359 , 0.18064516, 0.17763158]),\n",
       "  array([0.07432432, 0.17948718, 0.12582781, 0.16339869, 0.05263158]),\n",
       "  array([0.11409396, 0.08917197, 0.15686275, 0.08163265, 0.1192053 ]),\n",
       "  array([0.07843137, 0.05844156, 0.06578947, 0.03333333, 0.11258278])],\n",
       " 1.43: [array([0.12258065, 0.08917197, 0.15483871, 0.12418301, 0.08163265]),\n",
       "  array([ 0.14102564, -0.02702703,  0.14935065,  0.09150327,  0.08      ]),\n",
       "  array([ 0.08333333,  0.04545455,  0.20754717, -0.00657895,  0.22147651]),\n",
       "  array([0.10666667, 0.06493506, 0.16551724, 0.11764706, 0.07432432]),\n",
       "  array([0.11538462, 0.03225806, 0.10596026, 0.09333333, 0.16666667]),\n",
       "  array([0.06666667, 0.10897436, 0.1483871 , 0.11486486, 0.18064516]),\n",
       "  array([0.10666667, 0.00653595, 0.1483871 , 0.20779221, 0.15686275]),\n",
       "  array([0.125     , 0.04666667, 0.1038961 , 0.16107383, 0.15384615]),\n",
       "  array([0.14765101, 0.06369427, 0.10596026, 0.10738255, 0.08783784]),\n",
       "  array([0.07189542, 0.03267974, 0.18831169, 0.07843137, 0.09803922])],\n",
       " 1.67: [array([0.07894737, 0.07741935, 0.14473684, 0.18064516, 0.04697987]),\n",
       "  array([0.07843137, 0.01973684, 0.14935065, 0.09090909, 0.1409396 ]),\n",
       "  array([0.06535948, 0.01960784, 0.15584416, 0.04635762, 0.21192053]),\n",
       "  array([0.13333333, 0.06493506, 0.18954248, 0.11111111, 0.06578947]),\n",
       "  array([0.03896104, 0.07189542, 0.10596026, 0.10897436, 0.0794702 ]),\n",
       "  array([0.06040268, 0.07843137, 0.18831169, 0.07333333, 0.18300654]),\n",
       "  array([0.0516129 , 0.0516129 , 0.16883117, 0.19354839, 0.13157895]),\n",
       "  array([0.09333333, 0.12025316, 0.07792208, 0.1       , 0.11842105]),\n",
       "  array([0.13245033, 0.05128205, 0.09803922, 0.15333333, 0.02013423]),\n",
       "  array([0.07051282, 0.03267974, 0.13071895, 0.08783784, 0.04      ])],\n",
       " 2: [array([0.11688312, 0.00649351, 0.12258065, 0.13461538, 0.1038961 ]),\n",
       "  array([0.16666667, 0.02614379, 0.1372549 , 0.16883117, 0.10067114]),\n",
       "  array([0.06451613, 0.11764706, 0.04666667, 0.04545455, 0.18589744]),\n",
       "  array([0.09677419, 0.04      , 0.11842105, 0.13071895, 0.11409396]),\n",
       "  array([0.04605263, 0.06493506, 0.14935065, 0.09032258, 0.07843137]),\n",
       "  array([0.05333333, 0.07189542, 0.09868421, 0.00671141, 0.1589404 ]),\n",
       "  array([0.06535948, 0.02013423, 0.06493506, 0.09210526, 0.11333333]),\n",
       "  array([0.09210526, 0.11538462, 0.19463087, 0.04605263, 0.0516129 ]),\n",
       "  array([0.09032258, 0.06493506, 0.09868421, 0.09615385, 0.1       ]),\n",
       "  array([0.02666667, 0.13461538, 0.11764706, 0.05263158, 0.10457516])],\n",
       " 2.5: [array([0.        , 0.04516129, 0.0472973 , 0.07189542, 0.06578947]),\n",
       "  array([0.07741935, 0.02      , 0.08441558, 0.12337662, 0.05333333]),\n",
       "  array([0.00662252, 0.02649007, 0.09150327, 0.08441558, 0.10204082]),\n",
       "  array([0.06410256, 0.01315789, 0.10526316, 0.14102564, 0.07843137]),\n",
       "  array([0.06410256, 0.10828025, 0.08441558, 0.0955414 , 0.07792208]),\n",
       "  array([0.03378378, 0.07843137, 0.08552632, 0.09395973, 0.12337662]),\n",
       "  array([0.14      , 0.05844156, 0.22012579, 0.13548387, 0.08      ]),\n",
       "  array([0.05298013, 0.05806452, 0.11038961, 0.12258065, 0.09433962]),\n",
       "  array([0.07894737, 0.02580645, 0.07792208, 0.04827586, 0.12666667]),\n",
       "  array([0.05806452, 0.10457516, 0.08441558, 0.10322581, 0.05882353])],\n",
       " 3: [array([0.07843137, 0.05333333, 0.06493506, 0.06578947, 0.0794702 ]),\n",
       "  array([0.07142857, 0.03246753, 0.10457516, 0.11486486, 0.10596026]),\n",
       "  array([0.07236842, 0.08552632, 0.1372549 , 0.07236842, 0.125     ]),\n",
       "  array([0.05844156, 0.        , 0.11184211, 0.12738854, 0.08724832]),\n",
       "  array([0.10322581, 0.02614379, 0.11538462, 0.14102564, 0.13157895]),\n",
       "  array([0.03921569, 0.04516129, 0.16339869, 0.10828025, 0.06451613]),\n",
       "  array([ 0.07792208, -0.00657895,  0.09868421,  0.15384615,  0.10457516]),\n",
       "  array([0.03947368, 0.0130719 , 0.08496732, 0.10457516, 0.05333333]),\n",
       "  array([0.01324503, 0.02631579, 0.0974026 , 0.10625   , 0.05806452]),\n",
       "  array([0.0397351 , 0.05095541, 0.13815789, 0.0794702 , 0.04635762])],\n",
       " 4: [array([ 0.10062893,  0.03225806,  0.07189542,  0.09210526, -0.01298701]),\n",
       "  array([0.05732484, 0.02649007, 0.07843137, 0.10596026, 0.06122449]),\n",
       "  array([ 0.03225806, -0.01333333,  0.08      ,  0.05921053,  0.09271523]),\n",
       "  array([0.06622517, 0.03896104, 0.09803922, 0.11409396, 0.0794702 ]),\n",
       "  array([0.10322581, 0.06493506, 0.11842105, 0.11688312, 0.05921053]),\n",
       "  array([0.05194805, 0.02614379, 0.08609272, 0.13907285, 0.09868421]),\n",
       "  array([ 0.14556962, -0.02      ,  0.12337662,  0.12101911,  0.10526316]),\n",
       "  array([0.05442177, 0.04575163, 0.06081081, 0.05844156, 0.07843137]),\n",
       "  array([0.07096774, 0.02649007, 0.11764706, 0.09933775, 0.07843137]),\n",
       "  array([0.03267974, 0.00653595, 0.04635762, 0.0397351 , 0.02631579])],\n",
       " 5: [array([0.05921053, 0.        , 0.11842105, 0.08917197, 0.07333333]),\n",
       "  array([0.07051282, 0.01298701, 0.11038961, 0.06666667, 0.02702703]),\n",
       "  array([ 0.06451613, -0.04      ,  0.15822785,  0.11464968,  0.09090909]),\n",
       "  array([ 0.07843137, -0.00675676,  0.04605263,  0.04605263,  0.05442177]),\n",
       "  array([0.05882353, 0.00666667, 0.07792208, 0.13924051, 0.03333333]),\n",
       "  array([0.10759494, 0.06578947, 0.1038961 , 0.11409396, 0.09395973]),\n",
       "  array([0.05263158, 0.01298701, 0.08609272, 0.06578947, 0.09090909]),\n",
       "  array([0.05732484, 0.06451613, 0.12101911, 0.06578947, 0.07792208]),\n",
       "  array([0.05263158, 0.02614379, 0.14193548, 0.0794702 , 0.0794702 ]),\n",
       "  array([0.05333333, 0.03846154, 0.11764706, 0.04      , 0.02040816])],\n",
       " 6: [array([0.08441558, 0.00657895, 0.08496732, 0.17307692, 0.12658228]),\n",
       "  array([0.12418301, 0.01342282, 0.1503268 , 0.12162162, 0.11764706]),\n",
       "  array([0.05806452, 0.04545455, 0.09090909, 0.10322581, 0.07142857]),\n",
       "  array([0.09615385, 0.01923077, 0.05960265, 0.06666667, 0.125     ]),\n",
       "  array([0.08609272, 0.02597403, 0.07051282, 0.08441558, 0.08609272]),\n",
       "  array([0.09150327, 0.0516129 , 0.09868421, 0.09868421, 0.06      ]),\n",
       "  array([0.1125    , 0.05063291, 0.1038961 , 0.10897436, 0.11842105]),\n",
       "  array([0.05228758, 0.02      , 0.11111111, 0.11392405, 0.06622517]),\n",
       "  array([0.06666667, 0.07792208, 0.15384615, 0.1656051 , 0.1038961 ]),\n",
       "  array([0.09150327, 0.03246753, 0.07894737, 0.11038961, 0.06122449])],\n",
       " 7: [array([0.09868421, 0.07692308, 0.09090909, 0.12820513, 0.0738255 ]),\n",
       "  array([0.08387097, 0.02580645, 0.07843137, 0.09150327, 0.03311258]),\n",
       "  array([0.05844156, 0.04635762, 0.12258065, 0.12025316, 0.0794702 ]),\n",
       "  array([0.13375796, 0.05844156, 0.08552632, 0.07894737, 0.08666667]),\n",
       "  array([0.10457516, 0.03311258, 0.11038961, 0.15822785, 0.07236842]),\n",
       "  array([0.06578947, 0.03246753, 0.09210526, 0.10967742, 0.15384615]),\n",
       "  array([0.12820513, 0.0397351 , 0.11538462, 0.05333333, 0.07333333]),\n",
       "  array([0.0794702 , 0.05228758, 0.07096774, 0.10457516, 0.03333333]),\n",
       "  array([ 0.04635762, -0.01324503,  0.09090909,  0.1474359 ,  0.08609272]),\n",
       "  array([0.10322581, 0.04545455, 0.09803922, 0.06081081, 0.08053691])],\n",
       " 8: [array([0.13207547, 0.00671141, 0.1038961 , 0.03333333, 0.10526316]),\n",
       "  array([0.10191083, 0.0130719 , 0.08387097, 0.09150327, 0.07432432]),\n",
       "  array([0.08552632, 0.03921569, 0.11392405, 0.03947368, 0.08053691]),\n",
       "  array([ 0.05882353, -0.01324503,  0.11612903,  0.05960265,  0.07189542]),\n",
       "  array([0.12258065, 0.01935484, 0.08      , 0.08387097, 0.05333333]),\n",
       "  array([0.08666667, 0.07894737, 0.10828025, 0.06081081, 0.00671141]),\n",
       "  array([0.11688312, 0.01290323, 0.09333333, 0.08496732, 0.14285714]),\n",
       "  array([0.08333333, 0.02649007, 0.06578947, 0.08280255, 0.05882353]),\n",
       "  array([ 0.02649007,  0.00662252,  0.09677419, -0.04026846,  0.07236842]),\n",
       "  array([0.08496732, 0.01973684, 0.02631579, 0.05960265, 0.07792208])],\n",
       " 9: [array([ 0.07432432, -0.01973684,  0.07843137,  0.09493671,  0.06756757]),\n",
       "  array([0.1038961 , 0.01315789, 0.08552632, 0.02      , 0.0974026 ]),\n",
       "  array([0.11612903, 0.04487179, 0.11464968, 0.07096774, 0.0516129 ]),\n",
       "  array([0.07792208, 0.01315789, 0.07843137, 0.03947368, 0.10457516]),\n",
       "  array([0.08496732, 0.        , 0.11538462, 0.02649007, 0.11688312]),\n",
       "  array([0.12578616, 0.01960784, 0.125     , 0.07843137, 0.05960265]),\n",
       "  array([0.11038961, 0.01315789, 0.09150327, 0.06535948, 0.12820513]),\n",
       "  array([0.09803922, 0.04575163, 0.1038961 , 0.04635762, 0.10596026]),\n",
       "  array([ 0.05921053, -0.00653595,  0.07843137,  0.07692308,  0.06578947]),\n",
       "  array([0.0738255 , 0.02649007, 0.15483871, 0.00666667, 0.06493506])],\n",
       " 10: [array([ 0.05882353, -0.00653595,  0.06493506,  0.03896104,  0.04137931]),\n",
       "  array([ 0.11184211, -0.01986755,  0.0794702 ,  0.03355705,  0.12987013]),\n",
       "  array([ 0.04054054, -0.00662252,  0.07051282,  0.05228758,  0.01333333]),\n",
       "  array([0.06666667, 0.03333333, 0.07142857, 0.05960265, 0.0472973 ]),\n",
       "  array([0.04545455, 0.00657895, 0.07142857, 0.04516129, 0.01342282]),\n",
       "  array([ 0.04575163,  0.04575163,  0.0974026 ,  0.04697987, -0.00666667]),\n",
       "  array([0.10897436, 0.03246753, 0.08387097, 0.02027027, 0.00662252]),\n",
       "  array([0.06578947, 0.03205128, 0.02684564, 0.06493506, 0.03921569]),\n",
       "  array([ 0.06      , -0.01333333,  0.04575163,  0.10828025,  0.12903226]),\n",
       "  array([0.07236842, 0.0130719 , 0.04605263, 0.06493506, 0.04635762])],\n",
       " 12: [array([0.03896104, 0.04516129, 0.06329114, 0.0516129 , 0.03870968]),\n",
       "  array([ 0.02614379,  0.03870968,  0.03947368,  0.0397351 , -0.03311258]),\n",
       "  array([0.04458599, 0.07142857, 0.04666667, 0.06535948, 0.08917197]),\n",
       "  array([0.05263158, 0.03870968, 0.05263158, 0.05844156, 0.01333333]),\n",
       "  array([0.03921569, 0.03225806, 0.03870968, 0.03921569, 0.01324503]),\n",
       "  array([ 0.03289474,  0.03896104,  0.03289474,  0.01333333, -0.02      ]),\n",
       "  array([0.03870968, 0.        , 0.03870968, 0.07006369, 0.03821656]),\n",
       "  array([ 0.02614379, -0.00666667,  0.02013423,  0.07189542, -0.01315789]),\n",
       "  array([0.01324503, 0.03289474, 0.03947368, 0.03311258, 0.00662252]),\n",
       "  array([0.00662252, 0.02631579, 0.05844156, 0.06410256, 0.00657895])],\n",
       " 15: [array([0.03289474, 0.0130719 , 0.05882353, 0.05732484, 0.00657895]),\n",
       "  array([ 0.03267974, -0.05333333,  0.07189542,  0.02631579, -0.03355705]),\n",
       "  array([-0.01333333, -0.01315789,  0.07142857,  0.        , -0.01960784]),\n",
       "  array([-0.03355705,  0.        ,  0.06451613,  0.05194805, -0.03311258]),\n",
       "  array([-0.02684564, -0.01290323,  0.08974359,  0.02631579,  0.        ]),\n",
       "  array([ 0.02597403, -0.01960784,  0.09150327,  0.02      ,  0.        ]),\n",
       "  array([ 0.01973684, -0.00649351,  0.05228758,  0.02649007, -0.02614379]),\n",
       "  array([ 0.03267974,  0.        ,  0.03921569,  0.03333333, -0.04      ]),\n",
       "  array([ 0.03267974,  0.        ,  0.07096774,  0.02631579, -0.00666667]),\n",
       "  array([-0.03311258, -0.00649351,  0.07142857,  0.        , -0.01973684])],\n",
       " 18: [array([ 0.01973684, -0.02      ,  0.08280255,  0.02580645,  0.00653595]),\n",
       "  array([-0.01986755,  0.        ,  0.0516129 ,  0.02      , -0.03947368]),\n",
       "  array([ 0.02564103,  0.00641026,  0.06493506,  0.02631579, -0.03947368]),\n",
       "  array([ 0.02597403, -0.00649351,  0.05844156,  0.04666667, -0.0397351 ]),\n",
       "  array([ 0.02614379, -0.00657895,  0.05769231,  0.07051282, -0.01342282]),\n",
       "  array([ 0.0130719 ,  0.        ,  0.03267974,  0.03311258, -0.05298013]),\n",
       "  array([ 0.        , -0.03289474,  0.02      ,  0.02649007,  0.        ]),\n",
       "  array([ 0.        , -0.01298701,  0.03267974,  0.01960784, -0.01973684]),\n",
       "  array([ 0.01333333, -0.01973684,  0.08333333,  0.05128205, -0.04605263]),\n",
       "  array([-0.01333333, -0.01315789,  0.04635762,  0.02631579, -0.04      ])]}"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "chubby-conservative",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('parameter_guidelines/evaluation/german_credit/rel_undersampling_attack_utilities_fpattr{}_e{}.pkl'.format(fpattr, n_exp), 'wb') as outfile:\n",
    "    pickle.dump(results, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "metric-patch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.07142857, 0.00645161, 0.12582781, 0.1038961 , 0.02614379]),\n",
       " array([0.17006803, 0.01333333, 0.12666667, 0.13375796, 0.04794521]),\n",
       " array([0.03355705, 0.01324503, 0.14569536, 0.18867925, 0.11184211]),\n",
       " array([0.1       , 0.06451613, 0.07894737, 0.14285714, 0.20779221]),\n",
       " array([0.03378378, 0.04      , 0.21854305, 0.17721519, 0.29487179]),\n",
       " array([0.09803922, 0.01298701, 0.16666667, 0.15862069, 0.12337662]),\n",
       " array([0.07792208, 0.02580645, 0.12162162, 0.1025641 , 0.07189542]),\n",
       " array([0.11333333, 0.12258065, 0.15686275, 0.15584416, 0.22580645]),\n",
       " array([0.10625   , 0.05844156, 0.1       , 0.13664596, 0.08609272]),\n",
       " array([0.08441558, 0.08609272, 0.09210526, 0.10596026, 0.1038961 ])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3-FP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
